{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:21.522860Z",
     "iopub.status.busy": "2023-07-06T22:06:21.522479Z",
     "iopub.status.idle": "2023-07-06T22:06:21.532336Z",
     "shell.execute_reply": "2023-07-06T22:06:21.531204Z",
     "shell.execute_reply.started": "2023-07-06T22:06:21.522830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sacsasm/tweetsclass3.txt\n",
      "/kaggle/input/sacsasm/train.csv\n",
      "/kaggle/input/sacsasm/test.csv\n",
      "/kaggle/input/glove/glove.twitter.27B.25d.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:21.538177Z",
     "iopub.status.busy": "2023-07-06T22:06:21.537424Z",
     "iopub.status.idle": "2023-07-06T22:06:44.079246Z",
     "shell.execute_reply": "2023-07-06T22:06:44.078077Z",
     "shell.execute_reply.started": "2023-07-06T22:06:21.538144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: accelerate==0.20.3 in /opt/conda/lib/python3.10/site-packages (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3) (2.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.20.3) (3.0.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate==0.20.3) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate==0.20.3) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install accelerate==0.20.3\n",
    "os.environ['TORCH_USE_CUDA_DSA']=\"1\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.chdir('/kaggle/input/sacsasm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T00:02:53.199625Z",
     "iopub.status.busy": "2023-07-07T00:02:53.199262Z",
     "iopub.status.idle": "2023-07-07T00:02:53.378533Z",
     "shell.execute_reply": "2023-07-07T00:02:53.377567Z",
     "shell.execute_reply.started": "2023-07-07T00:02:53.199594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2267, 12)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:516\"\n",
    "\n",
    "def categorise(row):\n",
    "    if row['understatement'] == 1.0:\n",
    "        return 3\n",
    "    elif row['overstatement'] == 1.0:\n",
    "        return 4\n",
    "    elif row['rhetorical_question'] == 1.0:\n",
    "        return 5\n",
    "    elif row['irony'] == 1.0:\n",
    "        return 1\n",
    "    elif row['satire'] == 1.0:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "label_names = ['understatement','overstatement','rhetorical_question','irony','satire','sarcasm']\n",
    "train['label'] = train.apply(lambda row: categorise(row), axis=1)\n",
    "test['label'] = test.apply(lambda row: categorise(row), axis=1)\n",
    "train = train[train.sarcastic != 0]\n",
    "df_train = train[['tweet','label']]\n",
    "df_test = test[['text','label']]\n",
    "df_train = df_train.drop_duplicates()\n",
    "df_test = df_test.drop_duplicates()\n",
    "df_train = df_train.dropna()\n",
    "df_test =  df_test.dropna()\n",
    "\n",
    "df_train.rename(columns = {'tweet':'text'}, inplace = True)\n",
    "\n",
    "frames = [train, test]\n",
    "\n",
    "result = pd.concat(frames,ignore_index=True, sort=False)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T00:02:55.525857Z",
     "iopub.status.busy": "2023-07-07T00:02:55.525479Z",
     "iopub.status.idle": "2023-07-07T00:02:56.299567Z",
     "shell.execute_reply": "2023-07-07T00:02:56.298577Z",
     "shell.execute_reply.started": "2023-07-07T00:02:55.525830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-07T00:02:59.236731Z",
     "iopub.status.busy": "2023-07-07T00:02:59.236330Z",
     "iopub.status.idle": "2023-07-07T00:02:59.245584Z",
     "shell.execute_reply": "2023-07-07T00:02:59.244480Z",
     "shell.execute_reply.started": "2023-07-07T00:02:59.236693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1884\n",
       "1     147\n",
       "5     110\n",
       "2      65\n",
       "4      50\n",
       "3      11\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:22:27.551462Z",
     "iopub.status.busy": "2023-07-06T22:22:27.550709Z",
     "iopub.status.idle": "2023-07-06T22:22:27.568282Z",
     "shell.execute_reply": "2023-07-06T22:22:27.567240Z",
     "shell.execute_reply.started": "2023-07-06T22:22:27.551425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1878\n",
       "3    1295\n",
       "1    1194\n",
       "2    1032\n",
       "5     922\n",
       "4     749\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns 'text' and 'label'\n",
    "\n",
    "# Filter the DataFrame to exclude rows with label zero\n",
    "non_zero_df = result[result['label'].isin([1,2, 3, 4,5])]\n",
    "\n",
    "# Duplicate the rows in the filtered DataFrame\n",
    "duplicated_df = non_zero_df.sample(frac=1, replace=True)\n",
    "\n",
    "# Concatenate the original DataFrame and duplicated DataFrame\n",
    "result = pd.concat([result, duplicated_df], ignore_index=True)\n",
    "\n",
    "# Print the final DataFrame with duplicated rows\n",
    "result['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:21:15.049816Z",
     "iopub.status.busy": "2023-07-06T22:21:15.049434Z",
     "iopub.status.idle": "2023-07-06T22:21:15.066650Z",
     "shell.execute_reply": "2023-07-06T22:21:15.065714Z",
     "shell.execute_reply.started": "2023-07-06T22:21:15.049784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>I accidentally discovered a hidden talent for painting. Just a small stroke of luck.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>I slightly underestimated the spiciness of that dish. My taste buds got a surprise.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>The weather was mildly unpredictable. Gave me a chance to test my improvisation skills.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>I may have accidentally stayed up all night binge-watching a TV series. Time well spent, I suppose.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>The party was okay. We only danced like nobody was watching for a little while.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>I spotted a few shooting stars. Nature's way of reminding us to dream a little.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>I accidentally stumbled upon a beautiful park. A delightful oasis in the city.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>The traffic was mildly congested. Gave me time to enjoy some quality music.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>I think I blinked and missed a spectacular sunset. But hey, there's always tomorrow.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>I had a somewhat productive day. Accomplished a few things on my never-ending to-do list.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                     text  \\\n",
       "2321                 I accidentally discovered a hidden talent for painting. Just a small stroke of luck.   \n",
       "2322                  I slightly underestimated the spiciness of that dish. My taste buds got a surprise.   \n",
       "2323              The weather was mildly unpredictable. Gave me a chance to test my improvisation skills.   \n",
       "2324  I may have accidentally stayed up all night binge-watching a TV series. Time well spent, I suppose.   \n",
       "2325                      The party was okay. We only danced like nobody was watching for a little while.   \n",
       "2326                      I spotted a few shooting stars. Nature's way of reminding us to dream a little.   \n",
       "2327                       I accidentally stumbled upon a beautiful park. A delightful oasis in the city.   \n",
       "2328                          The traffic was mildly congested. Gave me time to enjoy some quality music.   \n",
       "2329                 I think I blinked and missed a spectacular sunset. But hey, there's always tomorrow.   \n",
       "2330            I had a somewhat productive day. Accomplished a few things on my never-ending to-do list.   \n",
       "\n",
       "      label  \n",
       "2321      3  \n",
       "2322      3  \n",
       "2323      3  \n",
       "2324      3  \n",
       "2325      3  \n",
       "2326      3  \n",
       "2327      3  \n",
       "2328      3  \n",
       "2329      3  \n",
       "2330      3  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the pandas DataFrame with column name is provided explicitly\n",
    "df = pd.read_csv(\"/kaggle/input/sacsasm/tweetsclass3.txt\", sep = \" \", names=['text'])\n",
    "df['label'] = 3\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# result.reset_index(drop=True, inplace=True)\n",
    "frames = [result , df]\n",
    "result = pd.concat(frames,ignore_index=True, sort=False)\n",
    "result.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:44.292401Z",
     "iopub.status.busy": "2023-07-06T22:06:44.292072Z",
     "iopub.status.idle": "2023-07-06T22:06:44.298750Z",
     "shell.execute_reply": "2023-07-06T22:06:44.297720Z",
     "shell.execute_reply.started": "2023-07-06T22:06:44.292371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_split_size_mb:516\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:21:18.395983Z",
     "iopub.status.busy": "2023-07-06T22:21:18.395607Z",
     "iopub.status.idle": "2023-07-06T22:21:18.404920Z",
     "shell.execute_reply": "2023-07-06T22:21:18.403901Z",
     "shell.execute_reply.started": "2023-07-06T22:21:18.395952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1878\n",
       "1     147\n",
       "5     110\n",
       "3      81\n",
       "2      65\n",
       "4      50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:44.314228Z",
     "iopub.status.busy": "2023-07-06T22:06:44.313831Z",
     "iopub.status.idle": "2023-07-06T22:06:44.325904Z",
     "shell.execute_reply": "2023-07-06T22:06:44.325014Z",
     "shell.execute_reply.started": "2023-07-06T22:06:44.314199Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "text_3 = result[result['label']==3]['text']\n",
    "text_3.to_csv('/kaggle/working/class3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:44.328047Z",
     "iopub.status.busy": "2023-07-06T22:06:44.327041Z",
     "iopub.status.idle": "2023-07-06T22:06:55.629798Z",
     "shell.execute_reply": "2023-07-06T22:06:55.628616Z",
     "shell.execute_reply.started": "2023-07-06T22:06:44.328016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweet-preprocessor\n",
      "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: tweet-preprocessor\n",
      "Successfully installed tweet-preprocessor-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:22:41.716212Z",
     "iopub.status.busy": "2023-07-06T22:22:41.715527Z",
     "iopub.status.idle": "2023-07-06T22:22:43.009335Z",
     "shell.execute_reply": "2023-07-06T22:22:43.008424Z",
     "shell.execute_reply.started": "2023-07-06T22:22:41.716180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffeine addiction</td>\n",
       "      <td>1</td>\n",
       "      <td>The only thing I got from college is a caffeine addiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question mark next to my answer on an exam because I’m always like yeah I don’t either ¯\\_(ツ)_/¯</td>\n",
       "      <td>0</td>\n",
       "      <td>I love it when professors draw a big question mark next to my answer on an exam because I’m always like yeah I don’t either ¯\\_(ツ)_/¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies when Covid started getting real? I’ve gotten three in regards to support for protests. And only @SavageXFenty shared helpful links and actually said black lives matter... we love capitalism 🥰🙌🏼</td>\n",
       "      <td>1</td>\n",
       "      <td>Remember the hundred emails from companies when Covid started getting real? I’ve gotten three in regards to support for protests. And only shared helpful links and actually said black lives matter... we love capitalism 🥰🙌🏼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not “forced” to go to college 🙃 okay sure sureeee</td>\n",
       "      <td>0</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to go to college 🙃 okay sure sureeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I did too, and I also reported Cancun Cruz not worrying about the heartbeats of his constituents without electricity or heat when he fled to Mexico.</td>\n",
       "      <td>0</td>\n",
       "      <td>I did too, and I also reported Cancun Cruz not worrying about the heartbeats of his constituents without electricity or heat when he fled to Mexico.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                           text  \\\n",
       "0                                                                                                                                                                                     The only thing I got from college is a caffeine addiction   \n",
       "1                                                                                                         I love it when professors draw a big question mark next to my answer on an exam because I’m always like yeah I don’t either ¯\\_(ツ)_/¯   \n",
       "2  Remember the hundred emails from companies when Covid started getting real? I’ve gotten three in regards to support for protests. And only @SavageXFenty shared helpful links and actually said black lives matter... we love capitalism 🥰🙌🏼   \n",
       "3                                                                                                                                                              Today my pop-pop told me I was not “forced” to go to college 🙃 okay sure sureeee   \n",
       "4                                             @VolphanCarol @littlewhitty @mysticalmanatee I did too, and I also reported Cancun Cruz not worrying about the heartbeats of his constituents without electricity or heat when he fled to Mexico.   \n",
       "\n",
       "   label  \\\n",
       "0      1   \n",
       "1      0   \n",
       "2      1   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                                                                                                                                                text_preprocessed  \n",
       "0                                                                                                                                                                       The only thing I got from college is a caffeine addiction  \n",
       "1                                                                                           I love it when professors draw a big question mark next to my answer on an exam because I’m always like yeah I don’t either ¯\\_(ツ)_/¯  \n",
       "2  Remember the hundred emails from companies when Covid started getting real? I’ve gotten three in regards to support for protests. And only shared helpful links and actually said black lives matter... we love capitalism 🥰🙌🏼  \n",
       "3                                                                                                                                                Today my pop-pop told me I was not “forced” to go to college 🙃 okay sure sureeee  \n",
       "4                                                                            I did too, and I also reported Cancun Cruz not worrying about the heartbeats of his constituents without electricity or heat when he fled to Mexico.  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL,p.OPT.MENTION,p.OPT.NUMBER)\n",
    "\n",
    "#forming a separate feature for cleaned tweets\n",
    "for i,v in enumerate(result['text']):\n",
    "    result.loc[i,'text_preprocessed'] = p.clean(v)\n",
    "    \n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:22:46.187853Z",
     "iopub.status.busy": "2023-07-06T22:22:46.186948Z",
     "iopub.status.idle": "2023-07-06T22:22:46.196629Z",
     "shell.execute_reply": "2023-07-06T22:22:46.195714Z",
     "shell.execute_reply.started": "2023-07-06T22:22:46.187810Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(result['text_preprocessed'], result['label'], \n",
    "                                                            random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:56.706018Z",
     "iopub.status.busy": "2023-07-06T22:06:56.705397Z",
     "iopub.status.idle": "2023-07-06T22:06:56.714367Z",
     "shell.execute_reply": "2023-07-06T22:06:56.713406Z",
     "shell.execute_reply.started": "2023-07-06T22:06:56.705983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2097,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:56.716234Z",
     "iopub.status.busy": "2023-07-06T22:06:56.715869Z",
     "iopub.status.idle": "2023-07-06T22:06:56.725833Z",
     "shell.execute_reply": "2023-07-06T22:06:56.724938Z",
     "shell.execute_reply.started": "2023-07-06T22:06:56.716200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2097,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:56.727627Z",
     "iopub.status.busy": "2023-07-06T22:06:56.727296Z",
     "iopub.status.idle": "2023-07-06T22:06:56.735479Z",
     "shell.execute_reply": "2023-07-06T22:06:56.734548Z",
     "shell.execute_reply.started": "2023-07-06T22:06:56.727599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:56.737329Z",
     "iopub.status.busy": "2023-07-06T22:06:56.736833Z",
     "iopub.status.idle": "2023-07-06T22:06:56.746058Z",
     "shell.execute_reply": "2023-07-06T22:06:56.745008Z",
     "shell.execute_reply.started": "2023-07-06T22:06:56.737299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:56.748068Z",
     "iopub.status.busy": "2023-07-06T22:06:56.747654Z",
     "iopub.status.idle": "2023-07-06T22:06:59.571034Z",
     "shell.execute_reply": "2023-07-06T22:06:59.570016Z",
     "shell.execute_reply.started": "2023-07-06T22:06:56.748039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cf209a14474d88b7dbdbd74087c2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6f499d42d047b6ae8aceec5970aacd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c27104f2d7f40f48412e5448cfa6b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "PRETRAINED_LM = \"bert-base-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_LM, do_lower_case=True,model_max_length=512)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:06:59.573222Z",
     "iopub.status.busy": "2023-07-06T22:06:59.572603Z",
     "iopub.status.idle": "2023-07-06T22:06:59.579403Z",
     "shell.execute_reply": "2023-07-06T22:06:59.578007Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.573187Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode(docs):\n",
    "    '''\n",
    "    This function takes list of texts and returns input_ids and attention_mask of texts\n",
    "    '''\n",
    "    encoded_dict = tokenizer.batch_encode_plus(docs, add_special_tokens=True, max_length=512, padding='max_length',\n",
    "                            return_attention_mask=True, truncation=True,  return_token_type_ids=False,return_tensors='pt')\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    attention_masks = encoded_dict['attention_mask']\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T23:30:43.970197Z",
     "iopub.status.busy": "2023-07-06T23:30:43.969496Z",
     "iopub.status.idle": "2023-07-06T23:30:43.977756Z",
     "shell.execute_reply": "2023-07-06T23:30:43.976685Z",
     "shell.execute_reply.started": "2023-07-06T23:30:43.970164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1878\n",
       "3    1295\n",
       "1    1194\n",
       "2    1032\n",
       "5     922\n",
       "4     749\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:12:25.109749Z",
     "iopub.status.busy": "2023-07-06T22:12:25.109367Z",
     "iopub.status.idle": "2023-07-06T22:12:25.125460Z",
     "shell.execute_reply": "2023-07-06T22:12:25.124451Z",
     "shell.execute_reply.started": "2023-07-06T22:12:25.109720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2499\n",
       "1    2200\n",
       "2    2162\n",
       "0    1878\n",
       "4    1815\n",
       "5    1810\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:09:33.951023Z",
     "iopub.status.busy": "2023-07-06T22:09:33.950599Z",
     "iopub.status.idle": "2023-07-06T22:09:33.961655Z",
     "shell.execute_reply": "2023-07-06T22:09:33.960625Z",
     "shell.execute_reply.started": "2023-07-06T22:09:33.950993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1878\n",
       "1     147\n",
       "5     110\n",
       "3      81\n",
       "2      65\n",
       "4      50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:22:59.203574Z",
     "iopub.status.busy": "2023-07-06T22:22:59.203202Z",
     "iopub.status.idle": "2023-07-06T22:23:06.824216Z",
     "shell.execute_reply": "2023-07-06T22:23:06.823054Z",
     "shell.execute_reply.started": "2023-07-06T22:22:59.203537Z"
    }
   },
   "outputs": [],
   "source": [
    "train_input_ids, train_att_masks = encode(train_inputs.tolist())\n",
    "test_input_ids, test_att_masks = encode(test_inputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.616089Z",
     "iopub.status.idle": "2023-07-06T22:06:59.616838Z",
     "shell.execute_reply": "2023-07-06T22:06:59.616612Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.616589Z"
    }
   },
   "outputs": [],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:23:10.346319Z",
     "iopub.status.busy": "2023-07-06T22:23:10.345420Z",
     "iopub.status.idle": "2023-07-06T22:23:10.356686Z",
     "shell.execute_reply": "2023-07-06T22:23:10.354697Z",
     "shell.execute_reply.started": "2023-07-06T22:23:10.346275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6363]), torch.Size([707]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = torch.LongTensor(train_labels.tolist())\n",
    "test_y = torch.LongTensor(test_labels.tolist())\n",
    "train_y.size(),test_y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.620277Z",
     "iopub.status.idle": "2023-07-06T22:06:59.621037Z",
     "shell.execute_reply": "2023-07-06T22:06:59.620822Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.620801Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:23:16.098084Z",
     "iopub.status.busy": "2023-07-06T22:23:16.097718Z",
     "iopub.status.idle": "2023-07-06T22:23:16.105197Z",
     "shell.execute_reply": "2023-07-06T22:23:16.104058Z",
     "shell.execute_reply.started": "2023-07-06T22:23:16.098055Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_dataset = TensorDataset(train_input_ids, train_att_masks, train_y)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = TensorDataset(test_input_ids, test_att_masks, test_y)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.624624Z",
     "iopub.status.idle": "2023-07-06T22:06:59.625375Z",
     "shell.execute_reply": "2023-07-06T22:06:59.625160Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.625138Z"
    }
   },
   "outputs": [],
   "source": [
    "N_labels = len(result.label.unique())\n",
    "N_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.626734Z",
     "iopub.status.idle": "2023-07-06T22:06:59.627457Z",
     "shell.execute_reply": "2023-07-06T22:06:59.627240Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.627215Z"
    }
   },
   "outputs": [],
   "source": [
    "type(N_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:14:19.855542Z",
     "iopub.status.busy": "2023-07-06T22:14:19.855179Z",
     "iopub.status.idle": "2023-07-06T22:14:30.437025Z",
     "shell.execute_reply": "2023-07-06T22:14:30.435966Z",
     "shell.execute_reply.started": "2023-07-06T22:14:19.855505Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2545849d85db4f64b5be04d1313fbf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "N_labels = len(result.label.unique())\n",
    "model = BertForSequenceClassification.from_pretrained(PRETRAINED_LM,\n",
    "                                                      num_labels=N_labels,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.630986Z",
     "iopub.status.idle": "2023-07-06T22:06:59.631743Z",
     "shell.execute_reply": "2023-07-06T22:06:59.631499Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.631477Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'classifier' not in name: # classifier layer\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.633097Z",
     "iopub.status.idle": "2023-07-06T22:06:59.633877Z",
     "shell.execute_reply": "2023-07-06T22:06:59.633628Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.633606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify the frozen layers\n",
    "for name, param in model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        print(f'Parameter {name} is frozen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:14:35.807774Z",
     "iopub.status.busy": "2023-07-06T22:14:35.807390Z",
     "iopub.status.idle": "2023-07-06T22:14:35.839301Z",
     "shell.execute_reply": "2023-07-06T22:14:35.838178Z",
     "shell.execute_reply.started": "2023-07-06T22:14:35.807743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:14:37.385213Z",
     "iopub.status.busy": "2023-07-06T22:14:37.384851Z",
     "iopub.status.idle": "2023-07-06T22:14:42.947579Z",
     "shell.execute_reply": "2023-07-06T22:14:42.946607Z",
     "shell.execute_reply.started": "2023-07-06T22:14:37.385183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:14:50.237456Z",
     "iopub.status.busy": "2023-07-06T22:14:50.237007Z",
     "iopub.status.idle": "2023-07-06T22:14:50.261024Z",
     "shell.execute_reply": "2023-07-06T22:14:50.258726Z",
     "shell.execute_reply.started": "2023-07-06T22:14:50.237420Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
    "\n",
    "EPOCHS = 10\n",
    "# LEARNING_RATE = 2e-6\n",
    "\n",
    "# optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "             num_warmup_steps=0,\n",
    "            num_training_steps=len(train_dataloader)*EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T22:23:25.459011Z",
     "iopub.status.busy": "2023-07-06T22:23:25.458623Z",
     "iopub.status.idle": "2023-07-06T23:22:22.219420Z",
     "shell.execute_reply": "2023-07-06T23:22:22.218406Z",
     "shell.execute_reply.started": "2023-07-06T22:23:25.458982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec3043c350349e787eb202259072b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2236e09d76d497a9715a88fec256388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6460a27b564affbf23698af8f636e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2187822b587c4b39a46ffcd526d0626f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6f804e6b5b458ca1972e4fa27008aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584e6f1abf5d4127a32e6f20cf969524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3095ead39e41d8b48530f44d4eda94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdbc00428b84500b9e65ec55c48fb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954b71fdde804886ad3b35906734e232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ac3ed07ed2468799d5e0b6297e912d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "    print('Epoch: ', epoch_num + 1)\n",
    "    '''\n",
    "    Training\n",
    "    '''\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(tqdm(train_dataloader,desc='Training')):\n",
    "        input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "        output = model(input_ids = input_ids, attention_mask=att_mask,labels = labels)\n",
    "\n",
    "        loss = output.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        del loss\n",
    "\n",
    "        clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T23:29:29.142396Z",
     "iopub.status.busy": "2023-07-06T23:29:29.141915Z",
     "iopub.status.idle": "2023-07-06T23:29:42.137143Z",
     "shell.execute_reply": "2023-07-06T23:29:42.136150Z",
     "shell.execute_reply.started": "2023-07-06T23:29:29.142352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2dfceafc564b199000a3036b51f65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "test_pred = []\n",
    "test_f1 = 0.0\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in tqdm(enumerate(test_dataloader)):\n",
    "        input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "        output = model(input_ids = input_ids, attention_mask=att_mask)\n",
    "   \n",
    "        test_pred.append(np.argmax(output.logits.cpu().detach().numpy(),axis=-1))\n",
    "test_pred = np.concatenate(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-06T23:29:53.223602Z",
     "iopub.status.busy": "2023-07-06T23:29:53.222645Z",
     "iopub.status.idle": "2023-07-06T23:29:53.244281Z",
     "shell.execute_reply": "2023-07-06T23:29:53.243321Z",
     "shell.execute_reply.started": "2023-07-06T23:29:53.223567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score macro : 0.9914936455282356\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       199\n",
      "           1       0.97      1.00      0.99       111\n",
      "           2       1.00      1.00      1.00       117\n",
      "           3       1.00      1.00      1.00       109\n",
      "           4       1.00      1.00      1.00        72\n",
      "           5       0.96      1.00      0.98        99\n",
      "\n",
      "    accuracy                           0.99       707\n",
      "   macro avg       0.99      0.99      0.99       707\n",
      "weighted avg       0.99      0.99      0.99       707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = result.label.unique()\n",
    "print(\"f1 score macro :\",metrics.f1_score(test_y, test_pred, average = 'macro'))\n",
    "print(classification_report(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.649716Z",
     "iopub.status.idle": "2023-07-06T22:06:59.650526Z",
     "shell.execute_reply": "2023-07-06T22:06:59.650283Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.650260Z"
    }
   },
   "outputs": [],
   "source": [
    "list(result.label.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tried with Balanced CrossEntroyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.651925Z",
     "iopub.status.idle": "2023-07-06T22:06:59.652693Z",
     "shell.execute_reply": "2023-07-06T22:06:59.652451Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.652428Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_labels), y=result['label'].values)\n",
    "\n",
    "# Convert class weights to tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.654086Z",
     "iopub.status.idle": "2023-07-06T22:06:59.654828Z",
     "shell.execute_reply": "2023-07-06T22:06:59.654594Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.654561Z"
    }
   },
   "outputs": [],
   "source": [
    "class_weights_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.656225Z",
     "iopub.status.idle": "2023-07-06T22:06:59.656972Z",
     "shell.execute_reply": "2023-07-06T22:06:59.656760Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.656738Z"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.658383Z",
     "iopub.status.idle": "2023-07-06T22:06:59.659144Z",
     "shell.execute_reply": "2023-07-06T22:06:59.658930Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.658908Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "    print('Epoch: ', epoch_num + 1)\n",
    "    '''\n",
    "    Training\n",
    "    '''\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(tqdm(train_dataloader,desc='Training')):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "        output = model(input_ids = input_ids, attention_mask=att_mask,labels = labels)\n",
    "        loss_func = nn.CrossEntropyLoss(weight=class_weights_tensor,reduction='mean')\n",
    "        # Get the logits from the model's output\n",
    "        logits = output.logits\n",
    "        \n",
    "        # Compute the loss\n",
    "        \n",
    "        loss = loss_func(logits, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "#         if _%16==0:\n",
    "#             print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        del loss\n",
    "\n",
    "        clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.660572Z",
     "iopub.status.idle": "2023-07-06T22:06:59.661353Z",
     "shell.execute_reply": "2023-07-06T22:06:59.661113Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.661090Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_pred = []\n",
    "test_f1 = 0.0\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in tqdm(enumerate(test_dataloader)):\n",
    "        input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "        output = model(input_ids = input_ids, attention_mask=att_mask)\n",
    "   \n",
    "        test_pred.append(np.argmax(output.logits.cpu().detach().numpy(),axis=-1))\n",
    "test_pred = np.concatenate(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.662746Z",
     "iopub.status.idle": "2023-07-06T22:06:59.663481Z",
     "shell.execute_reply": "2023-07-06T22:06:59.663273Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.663251Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"f1 score macro :\",metrics.f1_score(test_y, test_pred, average = 'macro'))\n",
    "print(classification_report(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tried with Folcal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.664878Z",
     "iopub.status.idle": "2023-07-06T22:06:59.665619Z",
     "shell.execute_reply": "2023-07-06T22:06:59.665394Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.665372Z"
    }
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.criterion(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal_loss\n",
    "\n",
    "focal_loss = FocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.667032Z",
     "iopub.status.idle": "2023-07-06T22:06:59.667783Z",
     "shell.execute_reply": "2023-07-06T22:06:59.667540Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.667518Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "    print('Epoch: ', epoch_num + 1)\n",
    "    '''\n",
    "    Training\n",
    "    '''\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for step_num, batch_data in enumerate(tqdm(train_dataloader,desc='Training')):\n",
    "        input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "        output = model(input_ids = input_ids, attention_mask=att_mask,labels = labels)\n",
    "\n",
    "        # Get the logits from the model's output\n",
    "        logits = output.logits\n",
    "        loss = focal_loss(logits, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        model.zero_grad()\n",
    "        del loss\n",
    "\n",
    "        clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.669156Z",
     "iopub.status.idle": "2023-07-06T22:06:59.669916Z",
     "shell.execute_reply": "2023-07-06T22:06:59.669705Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.669682Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_pred = []\n",
    "test_f1 = 0.0\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in tqdm(enumerate(test_dataloader)):\n",
    "        input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "        output = model(input_ids = input_ids, attention_mask=att_mask)\n",
    "   \n",
    "        test_pred.append(np.argmax(output.logits.cpu().detach().numpy(),axis=-1))\n",
    "test_pred = np.concatenate(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.671276Z",
     "iopub.status.idle": "2023-07-06T22:06:59.672040Z",
     "shell.execute_reply": "2023-07-06T22:06:59.671821Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.671799Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"f1 score macro :\",metrics.f1_score(test_y, test_pred, average = 'macro'))\n",
    "print(classification_report(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bertweet experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.673436Z",
     "iopub.status.idle": "2023-07-06T22:06:59.674188Z",
     "shell.execute_reply": "2023-07-06T22:06:59.673973Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.673950Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.675543Z",
     "iopub.status.idle": "2023-07-06T22:06:59.676310Z",
     "shell.execute_reply": "2023-07-06T22:06:59.676095Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.676073Z"
    }
   },
   "outputs": [],
   "source": [
    "bertweet_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\") #bertweet-large\n",
    "bertweet_model = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.677693Z",
     "iopub.status.idle": "2023-07-06T22:06:59.678415Z",
     "shell.execute_reply": "2023-07-06T22:06:59.678204Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.678182Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, param in bertweet_model.named_parameters():\n",
    "    if 'classifier' not in name: # classifier layer\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.679805Z",
     "iopub.status.idle": "2023-07-06T22:06:59.680544Z",
     "shell.execute_reply": "2023-07-06T22:06:59.680329Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.680307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify the frozen layers\n",
    "for name, param in bertweet_model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        print(f'Parameter {name} is frozen.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.681959Z",
     "iopub.status.idle": "2023-07-06T22:06:59.682702Z",
     "shell.execute_reply": "2023-07-06T22:06:59.682459Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.682437Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode(docs):\n",
    "    '''\n",
    "    This function takes list of texts and returns input_ids and attention_mask of texts\n",
    "    '''\n",
    "    encoded_dict = bertweet_tokenizer.batch_encode_plus(docs, add_special_tokens=True, max_length=128, padding='max_length',\n",
    "                            return_attention_mask=True, truncation=True,  return_token_type_ids=False,return_tensors='pt')\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    attention_masks = encoded_dict['attention_mask']\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.684060Z",
     "iopub.status.idle": "2023-07-06T22:06:59.684823Z",
     "shell.execute_reply": "2023-07-06T22:06:59.684597Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.684564Z"
    }
   },
   "outputs": [],
   "source": [
    "train_input_ids_tweet, train_att_masks_tweet = encode(train_inputs.tolist())\n",
    "test_input_ids_tweet, test_att_masks_tweet = encode(test_inputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.686170Z",
     "iopub.status.idle": "2023-07-06T22:06:59.686921Z",
     "shell.execute_reply": "2023-07-06T22:06:59.686709Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.686687Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y = torch.LongTensor(train_labels.tolist())\n",
    "test_y = torch.LongTensor(test_labels.tolist())\n",
    "train_y.size(),test_y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.688256Z",
     "iopub.status.idle": "2023-07-06T22:06:59.689000Z",
     "shell.execute_reply": "2023-07-06T22:06:59.688788Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.688766Z"
    }
   },
   "outputs": [],
   "source": [
    "test_labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.690357Z",
     "iopub.status.idle": "2023-07-06T22:06:59.691122Z",
     "shell.execute_reply": "2023-07-06T22:06:59.690909Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.690886Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_dataset_tweet = TensorDataset(train_input_ids_tweet, train_att_masks_tweet, train_y)\n",
    "train_sampler_tweet = RandomSampler(train_dataset_tweet)\n",
    "train_dataloader_tweet = DataLoader(train_dataset_tweet, sampler=train_sampler_tweet, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset_tweet = TensorDataset(test_input_ids_tweet, test_att_masks_tweet, test_y)\n",
    "test_sampler_tweet = SequentialSampler(test_dataset_tweet)\n",
    "test_dataloader_tweet = DataLoader(test_dataset_tweet, sampler=test_sampler_tweet, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.692645Z",
     "iopub.status.idle": "2023-07-06T22:06:59.693392Z",
     "shell.execute_reply": "2023-07-06T22:06:59.693176Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.693154Z"
    }
   },
   "outputs": [],
   "source": [
    "bertweet_model = bertweet_model.cuda()\n",
    "bertweet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.694787Z",
     "iopub.status.idle": "2023-07-06T22:06:59.695505Z",
     "shell.execute_reply": "2023-07-06T22:06:59.695293Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.695270Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in bertweet_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in bertweet_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\n",
    "\n",
    "EPOCHS = 10\n",
    "# LEARNING_RATE = 2e-6\n",
    "\n",
    "# optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "             num_warmup_steps=0,\n",
    "            num_training_steps=len(train_dataloader_tweet)*EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.696906Z",
     "iopub.status.idle": "2023-07-06T22:06:59.697651Z",
     "shell.execute_reply": "2023-07-06T22:06:59.697424Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.697401Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "    print('Epoch: ', epoch_num + 1)\n",
    "    '''\n",
    "    Training\n",
    "    '''\n",
    "    bertweet_model.train()\n",
    "    train_loss = 0\n",
    "    total_samples = 0\n",
    "    for step_num, batch_data in enumerate(tqdm(train_dataloader_tweet,desc='Training')):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "        output = bertweet_model(input_ids = input_ids, attention_mask=att_mask,labels = labels)\n",
    "        loss_func = nn.CrossEntropyLoss(weight=class_weights_tensor,reduction='mean')\n",
    "        # Get the logits from the model's output\n",
    "        logits = output.logits\n",
    "        \n",
    "        # Compute the loss\n",
    "        \n",
    "        loss = loss_func(logits, labels)\n",
    "        train_loss += loss.item() * input_ids.size(0)\n",
    "        total_samples += input_ids.size(0)\n",
    "        loss.backward()\n",
    "        del loss\n",
    "\n",
    "        clip_grad_norm_(parameters=bertweet_model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    epoch_loss = train_loss / total_samples\n",
    "    print(f\"Training Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.699176Z",
     "iopub.status.idle": "2023-07-06T22:06:59.699948Z",
     "shell.execute_reply": "2023-07-06T22:06:59.699736Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.699714Z"
    }
   },
   "outputs": [],
   "source": [
    "bertweet_model.eval()\n",
    "test_pred = []\n",
    "test_f1 = 0.0\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in tqdm(enumerate(test_dataloader_tweet)):\n",
    "        input_ids, att_mask, labels = [data.to(device) for data in batch_data]\n",
    "        output = bertweet_model(input_ids = input_ids, attention_mask=att_mask)\n",
    "   \n",
    "        test_pred.append(np.argmax(output.logits.cpu().detach().numpy(),axis=-1))\n",
    "test_pred = np.concatenate(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.701308Z",
     "iopub.status.idle": "2023-07-06T22:06:59.702052Z",
     "shell.execute_reply": "2023-07-06T22:06:59.701842Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.701819Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"f1 score macro :\",metrics.f1_score(test_y, test_pred, average = 'macro'))\n",
    "print(classification_report(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LSTM experiment with weighted crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.703407Z",
     "iopub.status.idle": "2023-07-06T22:06:59.704170Z",
     "shell.execute_reply": "2023-07-06T22:06:59.703954Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.703931Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.utils import pad_sequences,to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.705508Z",
     "iopub.status.idle": "2023-07-06T22:06:59.706268Z",
     "shell.execute_reply": "2023-07-06T22:06:59.706051Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.706029Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer in the train text\n",
    "tokenizer.fit_on_texts(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.707637Z",
     "iopub.status.idle": "2023-07-06T22:06:59.708373Z",
     "shell.execute_reply": "2023-07-06T22:06:59.708163Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.708141Z"
    }
   },
   "outputs": [],
   "source": [
    "# get max length of the train data\n",
    "max_length = max([len(s.split()) for s in train_inputs])\n",
    "\n",
    "# pad sequences in x_train data set to the max length\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(train_inputs),\n",
    "                        maxlen = max_length)\n",
    "# pad sequences in x_test data set to the max length\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(test_inputs),\n",
    "                       maxlen = max_length)\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", train_labels.shape)\n",
    "\n",
    "print(\"y_train shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", test_labels.shape)\n",
    "\n",
    "# train_inputs, test_inputs, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.709758Z",
     "iopub.status.idle": "2023-07-06T22:06:59.710493Z",
     "shell.execute_reply": "2023-07-06T22:06:59.710278Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.710256Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import zeros\n",
    "# load embedding as a dict\n",
    "def load_embedding(filename):\n",
    "    # load embedding into memory, skip first line\n",
    "    file = open(filename,'r',encoding=\"utf-8\")\n",
    "    lines = file.readlines()\n",
    "    file.close()\n",
    "    # create a map of words to vectors\n",
    "    embedding = dict()\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        # key is string word, value is numpy array for vector\n",
    "        embedding[parts[0]] = asarray(parts[1:], dtype='float32')\n",
    "    return embedding\n",
    "\n",
    "# create a weight matrix for the Embedding layer from a loaded embedding\n",
    "def get_weight_matrix(embedding, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = zeros((vocab_size, embedding_dim))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        vector = embedding.get(word)\n",
    "        if vector is not None:\n",
    "            weight_matrix[i] = vector\n",
    "    return weight_matrix\n",
    "\n",
    "# contains the index for each word\n",
    "vocab = tokenizer.word_index\n",
    "# total number of words in our vocabulary, plus one for unknown words\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# embedding dimensions\n",
    "embedding_dim = 200\n",
    "\n",
    "# load embedding from file\n",
    "raw_embedding = load_embedding('/kaggle/input/glove/glove.twitter.27B.25d.txt')\n",
    "# get vectors in the right order\n",
    "embedding_matrix = get_weight_matrix(raw_embedding, vocab)\n",
    "\n",
    "print(\"Vocab size: \", vocab_size)\n",
    "print(\"Max text length: \", max_length)\n",
    "print(\"Embedding dim: \", embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.711878Z",
     "iopub.status.idle": "2023-07-06T22:06:59.712614Z",
     "shell.execute_reply": "2023-07-06T22:06:59.712378Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.712356Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, \n",
    "                            embedding_dim, \n",
    "                            weights = [embedding_matrix], \n",
    "                            input_length = max_length, \n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.713982Z",
     "iopub.status.idle": "2023-07-06T22:06:59.714757Z",
     "shell.execute_reply": "2023-07-06T22:06:59.714519Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.714497Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(units=128, dropout=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.716117Z",
     "iopub.status.idle": "2023-07-06T22:06:59.716859Z",
     "shell.execute_reply": "2023-07-06T22:06:59.716631Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.716609Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.718195Z",
     "iopub.status.idle": "2023-07-06T22:06:59.718951Z",
     "shell.execute_reply": "2023-07-06T22:06:59.718742Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.718719Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.720338Z",
     "iopub.status.idle": "2023-07-06T22:06:59.721102Z",
     "shell.execute_reply": "2023-07-06T22:06:59.720869Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.720847Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y_one_hot = to_categorical(train_labels, 6)\n",
    "test_y_one_hot = to_categorical(test_labels, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.722453Z",
     "iopub.status.idle": "2023-07-06T22:06:59.723215Z",
     "shell.execute_reply": "2023-07-06T22:06:59.723006Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.722983Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 200\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                              factor = 0.1,\n",
    "                              min_lr = 0.01)\n",
    "# train_inputs, test_inputs, train_labels, test_labels\n",
    "# train model\n",
    "history = model.fit(x_train, train_y_one_hot, batch_size = BATCH_SIZE, epochs = EPOCHS,\n",
    "                    validation_split = 0.1, verbose = 1, callbacks = [reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.724560Z",
     "iopub.status.idle": "2023-07-06T22:06:59.725301Z",
     "shell.execute_reply": "2023-07-06T22:06:59.725083Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.725061Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model_predictions = model.predict(x_test, batch_size = BATCH_SIZE, verbose = 1)\n",
    "predicted_labels = np.argmax(model_predictions, axis=1)\n",
    "\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.726683Z",
     "iopub.status.idle": "2023-07-06T22:06:59.727405Z",
     "shell.execute_reply": "2023-07-06T22:06:59.727192Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.727170Z"
    }
   },
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-07-06T22:06:59.728778Z",
     "iopub.status.idle": "2023-07-06T22:06:59.729512Z",
     "shell.execute_reply": "2023-07-06T22:06:59.729297Z",
     "shell.execute_reply.started": "2023-07-06T22:06:59.729275Z"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, test_y_one_hot, batch_size = BATCH_SIZE)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
